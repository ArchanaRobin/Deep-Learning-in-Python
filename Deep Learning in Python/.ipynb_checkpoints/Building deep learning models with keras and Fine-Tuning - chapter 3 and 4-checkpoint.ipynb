{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5b56ad",
   "metadata": {},
   "source": [
    "## Introduction to Deep Learning in Python\n",
    "\n",
    "In this chapter, you'll become familiar with the fundamental concepts and terminology used in deep learning, and understand why deep learning techniques are so powerful today. You'll build simple neural networks and generate predictions with them. This is the Summary of lecture \"Introduction to Deep Learning in Python\", via datacamp.\n",
    "\n",
    "\n",
    " - ### Building deep learning models with keras and Fine-Tuning - chapter 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ffd129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb71650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f915f",
   "metadata": {},
   "source": [
    "### 1. Creating a keras model\n",
    "Congrats. You've learned the theory of back-propagation, which is core to understanding deep learning. Now you'll learn how to create and optimize these networks using the Keras interface to the TensorFlow deep learning library.\n",
    "\n",
    "2. Model building steps\n",
    "The Keras workflow has 4 steps. First, you specify the architecture, which is things like: how many layers do you want? how many nodes in each layer? What activation function do you want to use in each layer? Next, you compile the model. This specifies the loss function, and some details about how optimization works. Then you fit the model. Which is that cycle of back-propagation and optimization of model weights with your data. And finally you will want to use your model to make predictions. We'll go through these steps sequentially. The first step is creating or specifying your model.\n",
    "\n",
    "3. Model specification\n",
    "Here is the code to do that. This code has three blocks. First we import what we will need. Numpy is here only for reading some data. The other two imports are used for building our model. The second block of two lines reads the data. We read the data here so we can find the number of nodes in the input layer. That is stored as the variable n_cols. We always need to specify how many columns are in the input when building a Keras model, because that is the number of nodes in the input layer. We then start building the model. The first line of model specification is model equals Sequential. There are two ways to build up a model, and we will focus on sequential, which is the easier way to build a model. Sequential models require that each layer has weights or connections only to the one layer coming directly after it in the network diagram. There are more exotic models out there with complex patterns of connections, but Sequential will do the trick for everything we need here. We start adding layers using the add method of the model. he type of layer you have seen, that standard layer type, is called a Dense layer. It is called Dense because all of the nodes in the previous layer connect to all of the nodes in the current layer. As you advance in deep learning, you may start using layers that aren't Dense. In each layer, we specify the number of nodes as the first positional argument, and the activation function we want to use in that layer using the keyword argument activation. Keras supports every activation function you will want in practice. In the first layer, we need to specify input shapes as shown here. That says the input will have n_cols columns, and there is nothing after the comma, meaning it can have any number of rows, that is, any number of data points. You'll notice the last layer has 1 node. That is the output layer, and it matches those diagrams where we ended with only a single node as the output or prediction of the model. This model has 2 hidden layers, and an output layer. You may be struck that each hidden layers has 100 nodes. Keras and TensorFlow do the math for us, so don't feel afraid to use much bigger networks than we've seen before. It's quite common to use 100 or 1000s nodes in a layer. You'll learn more about choosing an appropriate number of nodes later.\n",
    "\n",
    "\n",
    "- Model building steps\n",
    "    - Specify Architecture\n",
    "    - Compile\n",
    "    - Fit\n",
    "    - Predict\n",
    "\n",
    "> Note: In the lecture, keras framework was used. But in this page, keras with tensorflow (`tf.keras`) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77267d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/hourly_wages.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e608d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.024064</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>13.018727</td>\n",
       "      <td>17.822097</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.139097</td>\n",
       "      <td>0.384360</td>\n",
       "      <td>2.615373</td>\n",
       "      <td>12.379710</td>\n",
       "      <td>11.726573</td>\n",
       "      <td>0.498767</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\n",
       "count     534.000000  534.000000     534.000000      534.000000  534.000000   \n",
       "mean        9.024064    0.179775      13.018727       17.822097   36.833333   \n",
       "std         5.139097    0.384360       2.615373       12.379710   11.726573   \n",
       "min         1.000000    0.000000       2.000000        0.000000   18.000000   \n",
       "25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n",
       "50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n",
       "75%        11.250000    0.000000      15.000000       26.000000   44.000000   \n",
       "max        44.500000    1.000000      18.000000       55.000000   64.000000   \n",
       "\n",
       "           female        marr       south  manufacturing  construction  \n",
       "count  534.000000  534.000000  534.000000     534.000000    534.000000  \n",
       "mean     0.458801    0.655431    0.292135       0.185393      0.044944  \n",
       "std      0.498767    0.475673    0.455170       0.388981      0.207375  \n",
       "min      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n",
       "75%      1.000000    1.000000    1.000000       0.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c5177",
   "metadata": {},
   "source": [
    " note: There are 6 binary indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f6ada",
   "metadata": {},
   "source": [
    "#### Specifying a model\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called `df`. For convenience, everything in `df` except for the target has been converted to a NumPy matrix called `predictors`. The `target`, `wage_per_hour`, is available as a NumPy matrix called `target`.\n",
    "\n",
    "For all exercises in this chapter, we've imported the Sequential model constructor, the `Dense layer constructor`, and `panda`.\n",
    "\n",
    " - Store the number of columns in the predictors data to `n_cols`. This has been done for you.\n",
    " - Start by creating a Sequential model called `model`.\n",
    " - Use the `.add()` method on model to add a `Dense layer`.\n",
    " - Add 50 units, specify `activation='relu'`, and the input_shape parameter to be the tuple `(n_cols,)` which means it has `n_cols` items in each row of data, and any number of rows of data are acceptable as inputs.\n",
    " - Add another Dense layer. This should have `32` units and a `'relu'` activation.\n",
    " - Finally, add an output layer, which is a Dense layer with a single node. Don't use any activation function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "796c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predictors = df.iloc[:, 1:].to_numpy()\n",
    "target = df.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9773b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5812b44",
   "metadata": {},
   "source": [
    "#### Compiling and fitting a model\n",
    "- Why you need to compile your model\n",
    "    - Specify the optimizer\n",
    "        - Many options and mathematically complex\n",
    "        - \"Adam\" is usually a good choice\n",
    "    - Loss function\n",
    "        - \"mean_squared_error\"\n",
    "- Fitting a model\n",
    "    - Applying backpropagation and gradient descent with your data to update the weights\n",
    "    - Scaling data before fitting can ease optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce090da3",
   "metadata": {},
   "source": [
    "#### Compiling the model\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. You can read more about 'adam' optimizer as well as other keras optimizers [here](https://keras.io/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer.\n",
    "\n",
    " - In this exercise, you'll use the Adam optimizer and the 'mean squared error loss function'. Go for it!\n",
    "Compile the model using `'model.compile()'`. Your optimizer should be `adam` and the loss should be `'mean_squared_error''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab2766c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d427e",
   "metadata": {},
   "source": [
    "#### Fitting the model\n",
    "You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called predictors and the data to be predicted is stored in a NumPy matrix called target. Your model is pre-written and it has been compiled with the code from the previous exercise.\n",
    "\n",
    " - Fit the model. Remember that the first argument is the predictive features (predictors), and the data to be predicted (target) is the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51b12c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples\n",
      "Epoch 1/10\n",
      "534/534 [==============================] - 0s 812us/sample - loss: 95.4852\n",
      "Epoch 2/10\n",
      "534/534 [==============================] - 0s 53us/sample - loss: 28.7481\n",
      "Epoch 3/10\n",
      "534/534 [==============================] - 0s 53us/sample - loss: 23.2881\n",
      "Epoch 4/10\n",
      "534/534 [==============================] - 0s 52us/sample - loss: 22.7344\n",
      "Epoch 5/10\n",
      "534/534 [==============================] - 0s 58us/sample - loss: 21.8967\n",
      "Epoch 6/10\n",
      "534/534 [==============================] - 0s 47us/sample - loss: 21.6268\n",
      "Epoch 7/10\n",
      "534/534 [==============================] - 0s 50us/sample - loss: 21.4207\n",
      "Epoch 8/10\n",
      "534/534 [==============================] - 0s 47us/sample - loss: 21.3315\n",
      "Epoch 9/10\n",
      "534/534 [==============================] - 0s 52us/sample - loss: 21.1719\n",
      "Epoch 10/10\n",
      "534/534 [==============================] - 0s 54us/sample - loss: 21.0623\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccac4f6",
   "metadata": {},
   "source": [
    "#### Model validation\n",
    "- Validation in deep learning\n",
    "    - Commonly use validation split rather than cross-validation\n",
    "    - Deep learning widely used on large datasets\n",
    "    - Single validation score is based on large amount of data, and is reliable\n",
    "- Experimentation\n",
    "    - Experiment with different architectures\n",
    "        - More layers\n",
    "        - Fewer layers\n",
    "        - Layers with more nodes\n",
    "        - Layers with fewer nodes\n",
    "        - Creating a great model requires experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9e15d",
   "metadata": {},
   "source": [
    "#### Classification models\n",
    "- Classification\n",
    "    - `categorical_crossentropy` loss function\n",
    "    - Similar to log loss: Lower is better\n",
    "    - Add `metrics=['accuracy']` to compile step for easy-to-understand diagnostics\n",
    "    - Output layers has separate node for each possible outcome, and uses `softmax` activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760ae81",
   "metadata": {},
   "source": [
    "#### Understanding your classification data\n",
    "Now you will start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic. You will use predictors such as `age`, `fare` and where each passenger embarked from to predict who will survive. This data is from [a tutorial on data science competitions](https://www.kaggle.com/c/titanic). Look [here](https://www.kaggle.com/c/titanic/data) for descriptions of the features.\n",
    "\n",
    "It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted. What was the maximum age of passengers on the Titanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bb86123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/titanic_all_numeric.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43386bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
       "std      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "             male  embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "count  891.000000               891.000000                891.000000   \n",
       "mean     0.647587                 0.188552                  0.086420   \n",
       "std      0.477990                 0.391372                  0.281141   \n",
       "min      0.000000                 0.000000                  0.000000   \n",
       "25%      0.000000                 0.000000                  0.000000   \n",
       "50%      1.000000                 0.000000                  0.000000   \n",
       "75%      1.000000                 0.000000                  0.000000   \n",
       "max      1.000000                 1.000000                  1.000000   \n",
       "\n",
       "       embarked_from_southampton  \n",
       "count                 891.000000  \n",
       "mean                    0.722783  \n",
       "std                     0.447876  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     1.000000  \n",
       "75%                     1.000000  \n",
       "max                     1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63672bd",
   "metadata": {},
   "source": [
    "#### Last steps in classification models\n",
    "You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called `df`. You'll take information about the passengers and predict which ones survived.\n",
    "\n",
    "The predictive variables are stored in a NumPy array `predictors`. The target to predict is in `df.survived`, though you'll have to manipulate it for keras. The number of predictive features is stored in `n_cols`.\n",
    "\n",
    "Here, you'll use the `'sgd'` optimizer, which stands for [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). \n",
    "\n",
    " - Convert df.survived to a categorical variable using the `to_categorical()` function.\n",
    " - Specify a Sequential model called `model`.\n",
    " - Add a Dense layer with `32 nodes`. Use `'relu'` as the activation and `(n_cols,)` as the `input_shape`.\n",
    " - Add the Dense output layer. Because there are two outcomes, it should have 2 units, and because it is a classification model, the activation should be `'softmax'.`\n",
    " - Compile the model, using `'sgd'` as the `optimizer`, `'categorical_crossentropy'` as the loss function, and `metrics=['accuracy']` to see the accuracy (what fraction of predictions were correct) at the end of each epoch.\n",
    " - Fit the model using the predictors and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd69642",
   "metadata": {},
   "source": [
    "![](img10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1606b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 98us/sample - loss: 2.1046 - acc: 0.6117\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 38us/sample - loss: 0.9097 - acc: 0.6083\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.6670 - acc: 0.6599\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 40us/sample - loss: 0.6784 - acc: 0.6588\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.6275 - acc: 0.6487\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.6283 - acc: 0.6779\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 46us/sample - loss: 0.6217 - acc: 0.6914\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 38us/sample - loss: 0.6186 - acc: 0.6712\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 36us/sample - loss: 0.6127 - acc: 0.6947\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 41us/sample - loss: 0.6048 - acc: 0.6958\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "predictors = df.iloc[:, 1:].astype(np.float32).to_numpy()\n",
    "target = df.survived.astype(np.float32).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(target)\n",
    "\n",
    "# Set up the model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d5c6f",
   "metadata": {},
   "source": [
    "note:  This simple model is generating an accuracy of 68!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff61c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "891/891 [==============================] - 0s 97us/sample - loss: 2.9885 - acc: 0.5859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ba30cf5b0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import necessary modules\n",
    "# import keras\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import Sequential\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation=\"relu\", input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639aa88a",
   "metadata": {},
   "source": [
    "note:This simple model is generating an accuracy of 68!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00bbaf",
   "metadata": {},
   "source": [
    "### Using models\n",
    "- Using models\n",
    "    - Save\n",
    "    - Load\n",
    "    - Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b2b9c",
   "metadata": {},
   "source": [
    "#### Making predictions\n",
    "The trained network from your previous coding exercise is now stored as `model`. New data to make predictions is stored in a NumPy array as `pred_data`. Use model to make predictions on your new data.\n",
    "\n",
    "In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues.\n",
    "\n",
    "\n",
    " - Create your predictions using the model's `.predict()` method on `pred_data`.\n",
    " - Use NumPy indexing to find the column corresponding to predicted probabilities of survival being True. This is the second column (index 1) of predictions. Store the result in `predicted_prob_true` and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4a02485",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.read_csv('./dataset/titanic_pred.csv').astype(np.float32).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0714e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42109585 0.8789825  1.         0.76114285 0.19928896 0.16346516\n",
      " 0.03473718 0.5408022  0.28003228 0.95457625 0.27483335 0.8189647\n",
      " 0.2222623  0.99696153 0.18526578 0.06200234 0.39950582 0.8554039\n",
      " 0.02754709 0.9610998  0.9941943  0.3005594  0.03681768 0.6297899\n",
      " 0.99993587 0.13277213 0.95598775 0.9997073  0.16551241 0.991178\n",
      " 0.6582447  0.9820514  0.15733558 0.35310975 0.49275684 0.9989371\n",
      " 0.47666565 0.18305124 0.93925697 0.8738927  0.44846612 0.5952049\n",
      " 0.8940082  0.08162446 0.5036478  0.04382496 0.9996954  0.11803766\n",
      " 0.810305   0.9999956  0.9983746  0.00121023 0.68184394 0.97692025\n",
      " 0.9037117  0.5620932  1.         0.8740641  0.7253479  0.15733558\n",
      " 0.33634073 0.6423458  0.9011141  0.9997248  0.64229417 0.2414116\n",
      " 0.76348424 0.9326472  0.26375124 0.6800975  0.27536914 0.9648536\n",
      " 0.05825315 0.03770554 0.86727893 0.57607955 0.5303529  0.47723708\n",
      " 0.17570634 0.99092406 0.80752563 0.1365806  0.61331856 0.40706867\n",
      " 0.2467424  0.840513   0.63497585 0.83026004 0.830222   0.83489937\n",
      " 0.14296989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:, 1]\n",
    "\n",
    "# Print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31061e",
   "metadata": {},
   "source": [
    "## Chapter 4: Fine-tuning keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e603e29",
   "metadata": {},
   "source": [
    "### Understanding model optimization\n",
    " - Why optimization is hard\n",
    "     - Simultaneously optimizing 1000s of parameters with complex relationships\n",
    "     - Updates may not improve model meaningfully\n",
    "     - Updates too small (if learning rate is low) or too large (if learning rate is high)\n",
    " - Vanishing gradients\n",
    "     - Occurs when many layers have very small slopes (e.g. due to being on flat part of tanh curve)\n",
    "     - In deep networks, updates to backprop were close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f04687",
   "metadata": {},
   "source": [
    "#### Why optimization is hard\n",
    "In practice, optimization is a hard problem. The optimal value for any one weight depends on the values of the other weights, and we are optimizing many weights at once. Even if the slope tells us which weights to increase, and which to decrease, our updates may not improve our model meaningfully. A small learning rate might cause us to make such small updates to the model's weights that our model doesn't improve materially. A very large learning rate might take us too far in the direction that seemed good. A smart optimizer like Adam helps, but optimization problems can still occur. The easiest way to see the effect of different learning rates is to use the simplest optimizer,\n",
    "\n",
    "\n",
    " -  Stochastic gradient descent\n",
    " \n",
    "Stochastic Gradient Descent, sometimes abbreviated to SGD. This optimizer uses a fixed learning rate. Learning rates around point-01 are common. But you can specify the learning rate you need with lr argument as shown here. We have a function that creates a new model here. We create models in a for loop, and each time around we compile the model using SGD with a different learning rate. We pass in the optimizer with the same argument where we previously passed the string for \"Adam\". In an exercise, you will compare the results of training models trained with low, medium and high learning rates. Even if your learning rate is well tuned, you can run into the so-called\n",
    "\n",
    "\n",
    " -  The dying neuron problem\n",
    " \n",
    "\"dying-neuron\" problem. This problem occurs when a neuron takes a value less than 0 for all rows of your data. Recall that, with the ReLU activation function, any node with a negative input value produces an output of 0, and it also has a slope of 0 as you see in this graph. Because the slope is 0, the slope of any weights flowing into that node are also 0. So those weights don't get updated. In other words, once the node starts always getting negative inputs, it may continue only getting negative inputs. It's contributing nothing to the model at this point, and hence the claim that the node or neuron is \"dead.\"At first, this might suggest using an activation function whose slope is never exactly zero. However, those types of functions were used for many years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547f42b",
   "metadata": {},
   "source": [
    "#### Question: Diagnosing optimization problems\n",
    "Which of the following could prevent a model from showing an improved loss in its first few epochs?\n",
    "\n",
    " - Answer : Learning rate too low, Learning rate too high, and Poor choice of activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35e281",
   "metadata": {},
   "source": [
    "#### Changing optimization parameters\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize.\n",
    "\n",
    "\n",
    " - Import `SGD` from `keras.optimizers`.\n",
    " - Create a list of learning rates to try optimizing with called `lr_to_test`. The learning rates in it should be `.000001, 0.01, and 1`.\n",
    " - Using a for loop to iterate over `lr_to_test`:\n",
    " - Use the `get_new_model()` function to build a new, unoptimized model.\n",
    " - Create an optimizer called `my_optimizer` using the `SGD()` constructor with keyword argument `lr=lr`.\n",
    " - Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use `'categorical_crossentropy'` for the loss parameter.\n",
    " - Fit your model using the `predictors` and `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b12272c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/titanic_all_numeric.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8637f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "predictors = df.iloc[:, 1:].astype(np.float32).to_numpy()\n",
    "target = to_categorical(df.iloc[:, 0].astype(np.float32).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b990033",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (10, )\n",
    "\n",
    "def get_new_model(input_shape = input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "920766cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Train on 891 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 496us/sample - loss: 3.4124\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 44us/sample - loss: 3.3789\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 47us/sample - loss: 3.3454\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 45us/sample - loss: 3.3122\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 49us/sample - loss: 3.2789\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 48us/sample - loss: 3.2458\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 47us/sample - loss: 3.2129\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 45us/sample - loss: 3.1800\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 45us/sample - loss: 3.1472\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 52us/sample - loss: 3.1146\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Train on 891 samples\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 590us/sample - loss: 1.5377\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 45us/sample - loss: 0.6934\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 47us/sample - loss: 0.6221\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 45us/sample - loss: 0.6149\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 46us/sample - loss: 0.6308\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 49us/sample - loss: 0.6171\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 47us/sample - loss: 0.5926\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 50us/sample - loss: 0.6004\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 53us/sample - loss: 0.6009\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 49us/sample - loss: 0.5877\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Train on 891 samples\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 1s 625us/sample - loss: 43441515404035.4531\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 47us/sample - loss: 0.6699\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 52us/sample - loss: 0.6723\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 48us/sample - loss: 0.6681\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 46us/sample - loss: 0.6699\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 50us/sample - loss: 0.6765\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 49us/sample - loss: 0.6815\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.6711\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 54us/sample - loss: 0.6700\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 43us/sample - loss: 0.6694\n"
     ]
    }
   ],
   "source": [
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n' % lr)\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = tf.keras.optimizers.SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Train on 891 samples\n",
      "891/891 [==============================] - 1s 562us/sample - loss: 2.8021\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Train on 891 samples\n",
      "891/891 [==============================] - 1s 626us/sample - loss: 1.5280\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Train on 891 samples\n",
      "891/891 [==============================] - 1s 616us/sample - loss: 5441140611.5939\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss=\"categorical_crossentropy\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f8d45",
   "metadata": {},
   "source": [
    "####  Model validation\n",
    "- Validation in deep learning\n",
    "    - Commonly use validation split rather than cross-validation\n",
    "    - Deep learning widely used on large datasets\n",
    "    - Single validation score is based on large amount of data, and is reliable\n",
    "- Experimentation\n",
    "    - Experiment with different architectures\n",
    "        - More layers\n",
    "        - Fewer layers\n",
    "        - Layers with more nodes\n",
    "        - Layers with fewer nodes\n",
    "        - Creating a great model requires experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d91d4a",
   "metadata": {},
   "source": [
    "#### Evaluating model accuracy on validation dataset\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as `model`. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch.\n",
    "\n",
    " - Compile your model using `'adam'` as the `optimizer` and `'categorical_crossentropy'` for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument `metrics=['accuracy']` in `model.compile()`.\n",
    " - Fit the model using the `predictors` and `target`. Create a validation split of `30% (or 0.3)`. This will be reported in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78364d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      " 32/623 [>.............................] - ETA: 1s - loss: 8.3339 - acc: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 560us/sample - loss: 1.8994 - acc: 0.5987 - val_loss: 0.8662 - val_acc: 0.5746\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 87us/sample - loss: 0.7801 - acc: 0.6469 - val_loss: 0.7007 - val_acc: 0.3993\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 78us/sample - loss: 0.6889 - acc: 0.5955 - val_loss: 0.5582 - val_acc: 0.7351\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 82us/sample - loss: 0.6639 - acc: 0.6597 - val_loss: 0.5625 - val_acc: 0.6978\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 82us/sample - loss: 0.6231 - acc: 0.6645 - val_loss: 0.6692 - val_acc: 0.7052\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 74us/sample - loss: 0.6643 - acc: 0.6774 - val_loss: 0.6321 - val_acc: 0.6604\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 70us/sample - loss: 0.6317 - acc: 0.6774 - val_loss: 0.5727 - val_acc: 0.7201\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 67us/sample - loss: 0.6116 - acc: 0.7127 - val_loss: 0.5429 - val_acc: 0.7351\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 74us/sample - loss: 0.6423 - acc: 0.6742 - val_loss: 0.5467 - val_acc: 0.7575\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 77us/sample - loss: 0.6261 - acc: 0.6886 - val_loss: 0.4822 - val_acc: 0.7649\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Specify the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e9ed1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 272us/sample - loss: 1.0930 - acc: 0.6308 - val_loss: 0.6834 - val_acc: 0.6045\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 61us/sample - loss: 0.6465 - acc: 0.6790 - val_loss: 0.6075 - val_acc: 0.6828\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 106us/sample - loss: 0.6545 - acc: 0.6742 - val_loss: 0.5733 - val_acc: 0.7015\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 61us/sample - loss: 0.6120 - acc: 0.6838 - val_loss: 0.5899 - val_acc: 0.7388\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 56us/sample - loss: 0.5862 - acc: 0.7159 - val_loss: 0.5091 - val_acc: 0.7463\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 66us/sample - loss: 0.5966 - acc: 0.6902 - val_loss: 0.5192 - val_acc: 0.7612\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 59us/sample - loss: 0.6995 - acc: 0.7175 - val_loss: 0.5468 - val_acc: 0.7463\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 58us/sample - loss: 0.7021 - acc: 0.6629 - val_loss: 0.5179 - val_acc: 0.7687\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 59us/sample - loss: 0.6265 - acc: 0.7159 - val_loss: 0.5053 - val_acc: 0.7127\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 59us/sample - loss: 0.5518 - acc: 0.7448 - val_loss: 0.5979 - val_acc: 0.6642\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, epochs=10, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ffa04",
   "metadata": {},
   "source": [
    "#### Early stopping: Optimizing the optimization\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for `epochs` in your call to `.fit()`, as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as `model`. As before, the data is pre-loaded as `predictors` and `target`.\n",
    "\n",
    " - Import `EarlyStopping` from `keras.callbacks`.\n",
    " - Compile the model, once again using `'adam'` as the `optimizer`, `'categorical_crossentropy'` as the `loss` function, and `metrics=['accuracy']` to see the accuracy at each epoch.\n",
    " - Create an EarlyStopping object called `early_stopping_monitor`. Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of `EarlyStopping()` to be 2.\n",
    " - Fit the model using the `predictors` and `target`. Specify the number of epochs to be `30` and use a `validation split of 0.3`. In addition, pass `[early_stopping_monitor]` to the callbacks parameter.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71f311b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s 593us/sample - loss: 0.8343 - acc: 0.6148 - val_loss: 0.7212 - val_acc: 0.6754\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 74us/sample - loss: 0.7105 - acc: 0.6164 - val_loss: 0.5921 - val_acc: 0.7052\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 78us/sample - loss: 0.6750 - acc: 0.6677 - val_loss: 0.6141 - val_acc: 0.6791\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 81us/sample - loss: 0.6800 - acc: 0.6517 - val_loss: 0.5342 - val_acc: 0.7425\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 70us/sample - loss: 0.6441 - acc: 0.6774 - val_loss: 0.5985 - val_acc: 0.7052\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 75us/sample - loss: 0.6899 - acc: 0.6533 - val_loss: 0.6880 - val_acc: 0.6418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ba5451910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Specify the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=30, validation_split=0.3,\n",
    "          callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceaaf0a",
   "metadata": {},
   "source": [
    "note: Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 7 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac67cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s 627us/sample - loss: 0.8706 - acc: 0.6067 - val_loss: 0.5610 - val_acc: 0.7015\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 69us/sample - loss: 0.6543 - acc: 0.6597 - val_loss: 0.5365 - val_acc: 0.7052\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 69us/sample - loss: 0.7582 - acc: 0.6421 - val_loss: 0.5424 - val_acc: 0.7201\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 69us/sample - loss: 0.6279 - acc: 0.6677 - val_loss: 0.5392 - val_acc: 0.7164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ba54f2f70>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss= \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks = [early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11505b",
   "metadata": {},
   "source": [
    "#### Experimenting with wider networks\n",
    "Now you know everything you need to begin experimenting with different models!\n",
    "\n",
    "A model called `model_1` has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called `model_2` which is similar to `model_1`, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument `verbose=False` in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient.\n",
    "\n",
    " - Create `model_2` to replicate `model_1`, but use 100 nodes instead of 10 for the first two Dense layers you add with the `'relu'` activation. Use 2 nodes for the `Dense` output layer with `'softmax'` as the `activation`.\n",
    " - Compile `model_2` as you have done with previous models: Using `'adam'` as the `optimizer`, `'categorical_crossentropy`' for the `loss`, and `metrics=['accuracy']`.\n",
    " - Hit `'Submit Answer'` to fit both the models and visualize which one gives better results! Notice the keyword argument `verbose=False` in `model.fit()`: This prints out fewer updates, since you'll be evaluating the models graphically instead of through text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84d43f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model_1.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bdc2bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88859dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = tf.keras.Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(tf.keras.layers.Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2,\n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2,\n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create th eplot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b');\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41810d1f",
   "metadata": {},
   "source": [
    " note: The blue model is the one you made, the red is the original model. Your model had a lower loss value, so it is the better model. Nice job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a4470bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd8f6e",
   "metadata": {},
   "source": [
    "#### Adding layers to a network\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called `model_1` as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code.\n",
    "\n",
    " - Specify a model called `model_2 `that is like `model_1`, but which has 3 hidden layers of 50 units instead of only 1 hidden layer.\n",
    " - Use input_shape to specify the input shape in the first hidden layer.\n",
    " - Use `'relu'` activation for the 3 hidden layers and `'softmax'` for the output layer, which should have 2 units.\n",
    " - Compile `model_2` as you have done with previous models: Using `'adam'` as the `optimizer`, `'categorical_crossentropy'` for the loss, and `metrics=['accuracy']`.\n",
    " - Hit `'Submit Answer'` to fit both the models and visualize which one gives better results! For both models, you should look for the best `val_loss` and `val_acc`, which won't be the last epoch for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5209be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_1.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b473d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 652\n",
      "Trainable params: 652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb94b19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the new model: model_2\n",
    "model_2 = tf.keras.Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(tf.keras.layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b');\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Validation score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4fb84a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHgCAYAAABJrX+JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABE5UlEQVR4nO3dd5iU5dnG4d9NlaIgig1UULGACsqKXRF2Yu9GwZIYNQY1dknUWGLvRqNGgzWyKHaDhgVErLHgUhWxIBbQKFgRRWnP98c9+7GMy+6wO++8M+9c53HssTv9HmX3mqdbCAERERFJliZxFyAiIiK5p4AXERFJIAW8iIhIAingRUREEkgBLyIikkAKeBERkQRqFncBubTmmmuGLl26xF2GiIhIXkyYMOHLEELH2m5LVMB36dKFqqqquMsQERHJCzP7eEW3qYteREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiLAlCnQpo1/F0kCBbyICPDoo/Djj/Dkk3FXIpIbCngREWDkSP/+zDPx1iGSKwp4ESl5n38OEydC+/bw2mswb17cFYk0ngJeREre6NH+/YILYMkSeOGFeOsRyQUFvIiUvMpKWHttOPlkaNUKxo6NuyKRxlPAi0hJW7wYxoyBvfbycN9tN43DSzIo4EWkpI0fD998A3vv7ZdTKZg+HWbPjrcukcZSwItISaushCZNPNgBysv9+7PPxleTSC4o4EWkpFVWwg47QIcOfnmrrWCttdRNL8VPAS8iJeuLL2DCBNhnn2XXNWnirfixYyGE+GoTaSwFvIiUrOrlcdXj79XKyz3833or/zWJ5IoCXkRKVvXyuF69lr++ehxe3fRSzBTwIlKSlixZtjyuScZfwvXXh80203p4KW4KeBEpSePHw9df/7J7vloq5Tva/fxzfusSyRUFvIiUpMzlcZlSKT9d7tVX81uXSK4o4EWkJI0cufzyuEy77w5Nm6qbXoqXAl5ESk718rgVdc8DtGsH22+viXZSvBTwIlJyVrQ8LlMqBVVVvpWtSLFRwItIyams9N3qttmm7vuVl8PSpfDcc/mpSySXFPAiUlLqWh6XafvtoW1bddNLcVLAi0hJqW95XE3Nm0PfvppoJ8VJAS8iJaV6edyvfpXd/VMpmDEDPvoo0rJEck4BLyIlpbLSu95XtDwuU/U6eXXTS7FRwItIyZgzx2fF1zw9rj6bbw7rradueik+CngRKRnZLo+rycxb8c8+6zPqRYqFAl5ESka2y+MypVLw1VcwaVI0dYlEQQEvIiVhyRJvwWezPC5T//7+Xd30UkwiDXgz28vM3jWzGWZ27gru09fMJpvZNDN7YWUeG6Vrr4Vx4/L9qiISlTfeyH55XKZ11oGtttJEOykukQW8mTUFbgP2BroDA82se8Z92gP/AA4IIfQAfp3tY6O0YAHce69/aj/pJPj++3y9sohEZWWXx2UqL4eXX/a/DyLFIMoWfB9gRghhZghhITAcODDjPkcCj4cQPgEIIcxZicdGplUrP4ji7LPhn/+ELbdU15xIsVvZ5XGZUik/G/7ll3Nbl0hUogz4TsCsGpdnp6+raVNgdTN73swmmNlvVuKxkWrdGq6/3n+ZW7XyX+4//AHmzctnFSKSC3PmeBd9Q7rnq+22m+9sp256KRZRBrzVcl3IuNwM6A3sC+wJXGhmm2b5WH8RsxPNrMrMqubOnduYemu1004+c3bwYLjrLm/NjxmT85cRkQg1ZHlcpjZt/O+BevOkWEQZ8LOB9Wtc7gx8Vst9RoUQfgghfAm8CPTM8rEAhBCGhBDKQghlHTt2zFnxNbVq5ZPuXnnFf8n33BNOOAG++y6SlxORHKteHrftto17nlTKP/BH0JYQybkoA/4NoJuZdTWzFsAAYETGff4N7GpmzcysNbA9MD3Lx+bd9tv7L/ef/+yT8LbcEkaNirsqEalL9fK4Pfdc+eVxmaq3rX322cbXJRK1yAI+hLAY+CMwGg/th0MI08xskJkNSt9nOjAKmAqMB+4KIby1osdGVevKWGUVuPpqePVVWG017/I77jj49tu4KxOR2jRmeVym3r2hfXt100txsBBqHdouSmVlZaGqqipvr/fzz3DppXDNNbD22jBkCOy7b95eXkSycPHFcPnlPtFujTUa/3yHHur72X/0kW9jKxInM5sQQiir7TbtZNcILVvCFVfAa6/50pv99oNjj4Vvvom7MhGpVlkJffrkJtzB18N/8okfIStSyBTwOVBW5p/oL7gAKiqgRw946qm4qxKRuXNX/vS4+uj4WCkWCvgcadkSLrsMxo+Hjh3hgAPgN7/xsT8Ricfo0RBCbsbfq228MXTpooCXwqeAz7Ftt/VJPRddBA8+6K35EbHP/xcpTblaHleTmXfTP/ccLF6cu+cVyTUFfARatIBLLvHW/Nprw4EHwtFH+3GTIpIfuVwelymV8n0w8jinV4pcCHDuub4Ner4o4CO0zTYe8pdcAg895K35J56IuyqR0lBV5R+qc9k9X61fP2/Jq5tesjVhgq+4mjQpf6+pgI9YixbeXV9VBeutB4ccAgMHwpdfxl2ZSLI19vS4uqy5pn+A13p4yVZFhc/VOuyw/L2mAj5PevaE11/3iXiPPQbdu/t3EYlGrpfHZUqlfMOr+fOjeX5JjsWLfU7W/vv7Rkn5ooDPo+bNfSndhAmw/vr+Se6II7SvtUiuzZ3b+NPj6lNeDosWwYsvRvcakgzPPOMbLR19dH5fVwEfg6228s1xrrjCx+S7d4dHHom7KpHkiGJ5XKZddvGtqzUOL/WpqPDN0KL891gbBXxMmjeH88+HiRN9Te3hh3uL/osv4q5MpPhVVvp+FL17R/caq6wCu+6qgJe6ff+9N+QOP9znZOWTAj5mW27p43hXXeW73/XoAcOHe+tDRFZelMvjMpWXw7Rp8L//Rfs6UryeeAIWLMh/9zwo4AtCs2a+PnLSJN8la+BAP9Di88/jrkyk+ES5PC5T9ba1mk0vK1JRAV27wk475f+1FfAFpHt3+O9/4dprYeRIb80/8IBa8yIro7LS16hHsTwuU8+evmRO3fRSm88+g2ef9dZ7HCcPKuALTLNmMHgwTJ4Mm24KRx0FBx+sLkCRbFUvj1tzzehfq0kT6N/fW/D6IC6Zhg+HpUv973gcFPAFavPN4eWX4frrfTyxRw/v6tEfEZEVq14el8vT4+qTSvkH8Lffzt9rSnGoqIDttoPNNovn9RXwBaxpUzj7bG/Nb7EFHHOM72v/2WdxVyZSmMaMiX55XKbycv+ucXipado0n1cVx+S6agr4IrDZZr6Zxo03+lhfjx7wr3+pNS+SKR/L4zJtuCF066ZxeFleRYU30gYMiK8GBXyRaNoUzjwTpk71pXXHHgv77Qeffhp3ZSKFYenS/C2Py5RKwfPPw8KF+X1dKUxLl8KwYf5vca214qtDAV9kunWDF16Am2/286h79IB771VrXqSqyg9xyvduYeDd9D/84OdNiLz0EsyaFW/3PCjgi1KTJnDaad6a79kTjjvOJxXNmhV3ZSLxyefyuEx77OG/l+qmF/Du+bZtfc5UnBTwRWyTTbwVf8stPka/5ZZw991qzUtpyufyuEzt2/trK+Dlp5/8bJFDD4XWreOtRQFf5Jo0gT/+Ed58E7bdFk44AfbaCz75JO7KRPLnyy9h/Ph4uuerlZd7Dd99F18NEr+nn/Z/A3F3z4MCPjE22sh3TLrtNt8Nb8st4c471ZqX0pCP0+Pqk0r55KrnnouvBolfRQWsu64P28RNAZ8gTZrAySd7a76sDE480ccjP/447spEolVZ6V3zZWXx1bDDDtCmjdbDl7KvvvJtxo880lc+xU0Bn0Bdu/ofmdtv93Pnt9xSs3slueJcHldTixaw++4ahy9ljzwCixYVRvc8KOATq0kTGDQI3nrLJwCdcor/IRRJmjiXx2VKpeC99zQHplQNHeoNqp49467EKeATbsMN4eqrYcIE3/1OJGmql8ftuWfclWjb2lI2cya88kp8J8fVRgFfAo480scHzz8fvv8+7mpEcquy0g/0iGN5XKYePXyClbrpS8+wYf79yCPjraMmBXwJMPOd7z7/HK68Mu5qRHKnenlcPk+Pq4uZt+LHjtWQWCkJwWfP9+0L668fdzXLKOBLRJ8+fhrdjTfChx/GXY1IbsRxelx9ysv9g8fUqXFXIvlSVeVzLwplcl01BXwJueoqaNYMBg+OuxKR3CiE5XGZqsfh1U1fOoYOhZYt4bDD4q5keQr4EtKpE5x3Hjz2mB9YI1LMCmV5XKb11oPu3TXRrlQsWgTDh8MBB0C7dnFXs7wC+rWQfDj7bNhgAzj9dFiyJO5qRBpuwgSYO7ewuuerpVJ+PsRPP8VdiUTtmWf832Ghdc+DAr7ktGoF114LU6bAPffEXY1IwxXS8rhMqZSH+3//G3clErWKCujQwc8AKTQK+BJ0+OGwyy7wl7/oYAwpXoW0PC7Tbrv5fBd10yfb99/Dk0/CEUf4ToaFRgFfgszgppt8pu/ll8ddjcjK+/JL3365ELvnAVZdFXbcURPtku7xx2HBAl+hVIgU8CWqd2849lhfH//++3FXI7JyCnF5XKZUCiZO9ANIJJkqKvwkzx12iLuS2ingS9iVV/rSjnPOibsSkZVTWQlrrFFYy+MylZf7h5Bx4+KuRKLw2Wd+RHchbU2bSQFfwtZZx8fhR4zQWKEUj5rL4wrhSM4V2W47WG01ddMn1YMP+ge4o46Ku5IVU8CXuDPO8ONlzzwTFi+OuxqR+hXy8riamjWDPfbQh+ekGjrUdwjddNO4K1kxBXyJW2UVuP56P1b2zjvjrkakfoW8PC5TKuVbQ3/wQdyVSC69+aYvNS7UyXXVFPDCwQfD7rvDhRfCN9/EXY1I3Sorfey9Y8e4K6lfKuXf1U2fLMOG+fDQEUfEXUndFPDy/8vmvv4aLr007mpEVuyrr3x5XKGcHlefbt38dDF10yfH0qUe8HvtVfgfMhXwAkCvXnDCCXDrrfDOO3FXI1K7YlgeV5OZt+LHjdPW0Enx4oswe3Zhbk2bSQEv/+/yy6F1a9+vXqQQFcPyuEyplA99TZgQdyWSC0OH+kZGBxwQdyX1U8DL/1trLR+HHzkSRo2KuxqR5S1d6v8uC315XKZ+/fy7uumL34IF8OijcOih3hgqdAp4Wc5pp8Emm8BZZ/kxiCKFYuLE4lgel2mttXwITBPtit/TT8O8ecXRPQ8KeMnQogXccANMnw533BF3NSLLFNPyuEzl5fDKK/DDD3FXIo1RUQHrrQd9+8ZdSXYU8PIL++/vf5Auvlj7aEvhKKblcZlSKVi4EF56Ke5KpKG+/NKHL488sniGiBTw8gtmcOONfpTsX/8adzUivoSzkE+Pq8+uu/q5D+qmL14PP+y7fRZL9zwo4GUFttoK/vAHuP12mDYt7mqk1I0Z45PsijXgW7WCnXfWRLtiVlHhfxd79oy7kuwp4GWFLr3Ul4OcdZavPRaJy8iRvjxuu+3irqThUimYOhW++CLuSmRlffABvPpqcbXeQQEvdVhzTR+HHzMG/vOfuKuRUlW9PO5Xvyqesc/aVG9bq1Z88Rk2zIcuBw6Mu5KVo4CXOp1yCmy2mbfiFy6MuxopRcW6PC5Tr17QoYMCvtiE4N3zffv6tsPFJNKAN7O9zOxdM5thZufWcntfM/vOzCanvy6qcduZZjbNzN4yswfNbJUoa5XaNW/uE+7ef9+3sRXJt8pK/16My+NqatoU+vf3iXYa8ioe48f7379i656HCAPezJoCtwF7A92BgWbWvZa7vhRC6JX+ujT92E7AaUBZCGFLoCkwIKpapW777OMHK1x6qbekRPKpenncWmvFXUnjlZfDp5/Cu+/GXYlkq6LCj9U+9NC4K1l5Ubbg+wAzQggzQwgLgeHAgSvx+GZAKzNrBrQGPougRsnSjTfC/Plw0UX131ckV6qXxxXL6XH10fGxxWXRIhg+3Pedb9cu7mpWXpQB3wmYVePy7PR1mXY0sylmVmlmPQBCCJ8C1wOfAP8DvgshjImwVqnHFlvAySfDkCE+E1gkH4p9eVymrl1h440V8MVizBjf4KYYu+ch2oC3Wq7LHHmaCGwYQugJ3AI8CWBmq+Ot/a7AekAbM6v1P7GZnWhmVWZWNVf9x5H661+hfXs480yNIUp+VJ8eV8zL4zKVl8Pzz+ush2JQUeH//op1/keUAT8bqDnnsDMZ3ewhhHkhhPnpn0cCzc1sTaAc+DCEMDeEsAh4HNipthcJIQwJIZSFEMo6FuMelkWkQwe45BI/2/rf/467Gkm6pCyPy5RKwfff++QtKVzz5sGTT8KAAX5GRzGKMuDfALqZWVcza4FPkhtR8w5mto6ZWfrnPul6vsK75ncws9bp2/sD0yOsVbI0aBB07w7nnAM//xx3NZJkkybBnDnJ6Z6v1q+fr6lWN31he/xx+Omn4u2ehwgDPoSwGPgjMBoP54dDCNPMbJCZDUrf7TDgLTObAvwdGBDc68CjeBf+m+k6h0RVq2SvWTP42998Z6ebb467GkmypCyPy7T66r4qQOvhC1tFhc+X2H77uCtpOAsJGkwtKysLVVVVcZdREvbfH154wdeHrr123NVIEu28s2+u9MYbcVeSe3/5C1xzja8SWG21uKuRTJ9+6pvaXHRR4R+4ZWYTQghltd2mneykQW64ARYsgAsuiLsSSaKvv4bXXkte93y18nJYssQ/JEvhefBBn0h81FFxV9I4CnhpkE03hVNPhbvv9rFSkVx65plkLY/LtNNO0Lq1xuEL1dChsMMO0K1b3JU0jgJeGuyii3wJyRlnaNmc5NbIkb5qo0+fuCuJRsuWsNtuCvhCNHWqfxXz5LpqCnhpsPbt4bLL4MUX4bHH4q5GkiKpy+MylZfDO+/A7NlxVyI1DRvmk4kPPzzuShpPAS+NcsIJsNVWMHiwLykRaaykLo/LpONjC8/SpR7we+0FSdhWRQEvjdKsGdx0E3z0ke9XL9JYSV0el2mrrfwAHXXTF47nn/cZ9EnongcFvORAv35w0EFw5ZXwmY4EkkaqrITevZO//NLMu+nHjtUclkJRUQGrruqHyySBAl5y4vrrfW/t88+PuxIpZklfHpcplfLhiDffjLsSWbAAHn0UDjsMWrWKu5rcUMBLTmy8sc+m/9e/krkxieRH9fK4pBwPW5/ycv+ucfj4PfWUnxGQlO55UMBLDv3lLz6mqGVz0lCVlcleHpepc2fYfHONwxeCigro1Al23z3uSnJHAS85s9pqcMUV8Mor8NBDcVcjxaZUlsdlSqV8Rzsd3hSfuXP9w+WRRybr354CXnLqd7+DXr3gT3+CH3+MuxopJpMnwxdflM74e7Xych//ffXVuCspXQ8/DIsXwzHHxF1JbingJaeaNvVT5mbN8ol3ItkqleVxmfr29d8bddPHp6ICtt7aly4miQJecm633Xwm6jXXaJcuyV6pLI/LtNpqvu+5Aj4eM2b4yo0kTa6rpoCXSFx3nZ+Wde65cVcixeCbb7yLutS656uVl0NVlf93kPwaNsz3JBg4MO5Kck8BL5Ho0gXOPtt/eV57Le5qpNAl/fS4+qRSvvJk3Li4KyktIfjJcXvs4SsakkYBL5E57zxYZx04/XT/4y2yIpWVsPrqsP32cVcSjz59fAc1rYfPr9dfhw8+SN7kumoKeIlM27Zw1VUwfjw88EDc1UihWrrUA77UlsfV1Ly5T7bTOHx+VVTAKqvAIYfEXUk0FPASqd/8BsrKfCz+hx/irkYKUakuj8uUSnlr8sMP466kNCxaBMOHw4EH+kTHJFLAS6SaNPHT5j791GfVi2SqXh63117x1hE3bVubX6NHw1dfJXP2fDUFvERu551hwACfWf/xx3FXI4WmshK23bb0lsdl2nxz3ypV3fT5MXQorLlmsvddUMBLXlxzjS9F+fOf465ECkmpL4+rycy76Z991peYSnS++w5GjPCGR/PmcVcTHQW85MUGG8Dgwb5H/csvx12NFIpSOz2uPuXlfmTu5MlxV5Jsjz8OP/2U7O55UMBLHv3pT94FecYZWjYnrtSXx2WqHodXN320Kipgk02Sf2qhAl7ypk0buPpqmDDBz42X0laqp8fVZe21fT90TbSLzuzZ8Nxz3no3i7uaaCngJa+OPNJba+efD99/H3c1EqcpU+DzzzX+nimV8mGsBQviriSZHnjAd7A76qi4K4meAl7yqkkTP23u8899ExwpXVoeV7tUys+Gf+mluCtJpooK2HFH76JPOgW85N3223v32I03alOPUqblcbXbdVdo0ULd9FGYOhXefDP5k+uqKeAlFldf7eOugwfHXYnE4dtvtTxuRdq0gZ120kS7KFRUQLNmcPjhcVeSHwp4iUWnTr597WOPwQsvxF2N5Nszz/habwV87VIpXyo3Z07clSTHkiU+/r733r7BTSlQwEtszjnH18effro29ig1lZXQvr2Wx61I9XI5HR+bO88/71tml0r3PCjgJUatWsG11/ps6nvuibsayZeap8c1axZ3NYWpd2//AKRu+typqPBDZfbfP+5K8kcBL7E6/HDfq/4vf/HtIyX5tDyufk2bQr9+HvAhxF1N8fvxRx8OPOwwb1iUCgW8xMrMT5ubOxcuvzzuaiQftDwuO6kUzJoF778fdyXF76mnfN+NUuqeBwW8FICyMjj2WF8fP2NG3NVI1CorYZttYJ114q6ksKVS/l3d9I03dCh07gy77x53JfmlgJeCcOWV0LKlT7wrBaXa7arlcdnbaCPo0kXr4Rtr7lzfEvmoo3yjrVJSYm9XCtW66/r2tf/+tx+XmUQffwx33+1HVK61FvTqBe+9F3dV+VW9PE6nx9Wv+vjYceNg8eK4qyleDz3k/+ZKrXseFPBSQM48E7p29dPmkvAH7dtv4Ykn4JRTYNNNvTV2wgnw4ouw556+ZGe77eA//4m70vzR8riVk0rBvHnwxhtxV1K8KiqgZ0/Ycsu4K8k/BbwUjFVWgeuug7fegjvvjLualbdwoYf3hRf6XtdrrAGHHOIn5226qU8mfOstD/aKCqiqgo039mU7l1+e/CN0Q1h2epyWx2WnXz9vyaubvmHefx9ef700W+8AFhI0GFhWVhaqqqriLkMaIQTYYw8Pwvff97PCC1UIMG2a//F95hnfke+HH3ycr08fb32lUt5abdGi9udYsABOPNED/5BD4L77YNVV8/o28mbyZJ9cd++9PqlSslNWBq1b+4dHWTkXXwyXXearETp1iruaaJjZhBBCWW236XO0FBQz+NvffKOPSy/1nwvJZ595oFd//e9/fv2mm8Jvf+uB3revd0Nno1UruP9+P3Rl8GDYYQefh5DEk660PK5hysvhhhtg/nxo2zbuaopHCP7BuX//5IZ7fdRFLwVnm23g+OPh1lvhnXfireX7732M/IwzoEcP/0Px2996WO2+u0+a+/hjePdduO02OOig7MO9mpnPPxg9Gr74wsflR42K4M3ETMvjGiaV8jkpOrNh5bz2GsycWbrd86CAlwJ1+eXeuj377Py+7uLFvozrsstgt92gQwfYbz/45z893K+9FiZN8iB+8EE47jjfTz8X+vf3cfkNN/RZ5ldfnZzldN9+C6+8ouVxDbHzzj4/RevhV05Fhf8NOfjguCuJj7ropSCtvbZPVvvTn7w1G1W3bgg+1v/MM/713HM+a9nMu83PPttbUNV/ZKPWpYsH4fHHw3nnwcSJvk9/sXfNjh2r0+MaapVV/Ix4TbTL3sKFvjzuwAN9//lSpYCXgnXaad5yPussb902b56b550719faV4f6rFl+fZcucMQRPubZr198R0q2bu3HWvbuDX/+sw9TPPmkb3xSrKqXx+2wQ9yVFKdUyj/sfvYZrLde3NUUvlGj4KuvSrt7HtRFLwWsZUufXDR9OtxxR8OfZ8ECGDPGJ7Fts41vMjNwIDz+uI933367b5E7cyYMGeIH4MR9XrSZ7+o3ahTMnu0zqceMibemhgrBAz6V0vK4hqretlat+OxUVEDHjr4ks5Qp4KWgHXCAt94vvtg/kWdjyRKYMMHHsPv396V2e+7pe923b+/j+6+/Dl9+6SdMDRrk69HNIn0rDZJK+bh8587evX3ddcU3Lj9liq82UPd8w229tQeWAr5+330HI0b4jpG56vUrVvo8LQWtetlcr17w17/CLbfUfr8PP/Tu9rFjvfv966/9+q228p3kyst90lybNvmqPHc22sgn/v3ud95NO3Ei3HVX8bwXLY9rvCZN/MPq2LH+Aa8QP4wWisceg59/Vvc8KOClCGy1lW8Gc/vt3tru0QO++cb36K4O9Q8+8Puut57vDJdK+R/EpCzJatPGJw317u2T76ZP921wu3aNu7L6VVb6B7R11427kuJWXg7Dh8Pbb/vvgNSuogK6dfPht1KngJeicOmlvixtwABf+jJhgm/t2ratbyxz2mke6ptvntzWjZlPuuvVy/87lJXBww/7B5lCVb087k9/iruS4lfz+FgFfO1mzYLnn/fevqT+HVgZGoOXotCxI1x1lbdcmzf3JXQvveRd8U895QG/xRal8Uu9555++Mi66/okohtvLNxx+erlcTo9rvE22MB3TNR6+BV74AH/XVD3vNNe9FJUliyBpk3jrqIwzJ/ve7o/9pifdT1kiC+xKyTHH++rFebO1Qz6XDjlFD+86OuvV3y+QakKwYfz2rWD//437mryp6696NWCl6KicF+mbVt45BG44gpvuey8s2+bWyiqT4/T8rjcSaX8QKPXXou7ksIzdaof/qTW+zIKeJEiZgbnnw9PP+0rCcrKfDe+QjB1qm/MouVxubPHHj6jXt30v1RR4R8kDz887koKhwJeJAH22cfH5Tt29FbeTTfFPy6v5XG5166dH0Ws9fDLW7LEe7H22QfWWCPuagpHpAFvZnuZ2btmNsPMzq3l9r5m9p2ZTU5/XVTjtvZm9qiZvWNm081sxyhrFSl23br5Bj777++n0/32t76LX1y0PC4aqRSMH+8rFMQ995z3Fh1zTNyVFJbIAt7MmgK3AXsD3YGBZta9lru+FELolf66tMb1NwOjQgibAz2B6VHVKpIUq67qk+4uvRSGDvVDSj75JP91fPedT3RS93zulZf7EtHnn4+7ksJRUeGHyuy3X9yVFJYoW/B9gBkhhJkhhIXAcODAbB5oZqsBuwF3A4QQFoYQvo2qUJEkadLElxGOGOEn5ZWV5f8scZ0eF50ddvCNjzQO73780T/U/vrX+TnxsZhEGfCdgFk1Ls9OX5dpRzObYmaVZla9fcNGwFzgXjObZGZ3mVmRbMwpUhj239+7cjt08Fbfrbfmb1y+stLHi3fUwFrOtWjhmzsp4N2IEb5kVLPnf6negDezTc3sWTN7K315azO7IIvnrm3Lkcw/LxOBDUMIPYFbgCfT1zcDtgVuDyFsA/wA/GIMP13PiWZWZWZVc+fOzaIskdKx2WY+Lr/33nDqqXDccfDTT9G+pk6Pi155uffOFNKyyLgMHQrrr+9nTcjysmnB3wmcBywCCCFMBQZk8bjZwPo1LncGPqt5hxDCvBDC/PTPI4HmZrZm+rGzQwivp+/6KB74vxBCGBJCKAshlHXs2DGLskRKS7t2fp78xRfDfff5H8LZs6N7PS2Pi56Oj3Vz5sDo0b7RUxOtCfuFbP6TtA4hjM+4bnEWj3sD6GZmXc2sBf6hYETNO5jZOma+uaiZ9UnX81UI4XNglpltlr5rf+DtLF5TRGrRpInvz/3EE77db+/e8PLL0byWlsdFr3t3X51Q6t30Dz3kcz3UPV+7bAL+SzPbmHT3upkdBvyvvgeFEBYDfwRG4zPgHw4hTDOzQWY2KH23w4C3zGwK8HdgQFi2d+6pwDAzmwr0Aq7M/m2JSG0OOsi77Nu1801Tbr899+PylZXQs6ef7CfRMPNu+mef9Rn1paqiwpdi6vCd2mUzQnYKMATY3Mw+BT4EjsrmydPd7iMzrrujxs+3Areu4LGTgVr31xWRhuve3SffHX00nHyyn8x3223QsmXjn7t6edzgwY1/LqlbKuXjz1OmwDbbxF1N/r37rv87vv76uCspXHW24NNr2U8KIZQDHYHNQwi7hBA0tUOkiLVv77OPL7gA7r7bZ2V/9ll9j6qfTo/Ln+pjgkt1HH7YMB96Gjgw7koKV50BH0JYAvRO//xDCOH7vFQlIpFr0gQuu8zXEL/5po/Lv/JK455Ty+PyZ731vGu6FMfhQ/Du+f79NRRUl2zG4CeZ2QgzO8bMDqn+irwyEcmLQw7x08natPGW/JAhDXsenR6Xf6kUvPRS9EsfC82rr/rhSppcV7dsAr4D8BXQD9g//aUNAUUSZMst/bCa/v3hD3+AQYNg4cKVe44334RPP9XyuHwqL/dwL6Xzz8Fb761awcEHx11JYav3c3YI4Xf5KERE4rX66n7s7AUXwNVXe2A/+mj2h8VoeVz+7b47NG/u3fTVY/JJt3ChL4876CA/e0FWLJud7Dqb2RNmNsfMvjCzx8yscz6KE5H8atoUrroKHn4YJk/2fexfey27x2p5XP61bevzHUppHL6yEr7+Wt3z2cimi/5efIOa9fC95J9KXyciCfXrX/s4Z8uW3kq866667z9vnk6Pi0t5OUyaBF9+GXcl+VFRAR07wq9+FXclhS+bgO8YQrg3hLA4/XUfvmRORBJs662hqsoD/ve/9zXzKxqXHzsWFi9WwMchlfIJjuPGxV1J9L79Fp56ypfGaSJn/bLdye5oM2ua/joan3QnIgnXoQOMHOkb19x+u4/zfv75L+9XWenncWt5XP6VlfnSxFJYD//YY/Dzz+qez1Y2AX8ccDjwOb5F7WHp60SkBDRrBtdeCw8+6LvelZX5DmLVap4e17x5fHWWqmbNfNvhZ57J33HAcRk6FDbd1P8NSv3qDfgQwichhANCCB1DCGuFEA7STnYipWfAAB+Xb97cT6S7Nz0TR8vj4pdKwUcfwQcfxF1JdD75BF54AY45xvfil/plM4v+X2bWvsbl1c3snkirEpGC1LOnj8vvsoufLX/qqb7lLWh5XJzKy/17krvpH3jAvx95ZLx1FJNspilsHUL4tvpCCOEbMyvBow1EBGCNNXzHunPPhRtu8NbU1ltDp05xV1a6unWDDTbwbvpBg+q/f7EJwbvnd94ZNtoo7mqKRzZj8E3MbPXqC2bWgew+GIhIQjVr5qd4DRvmS+kOPzzuikpb9fGx48b5YT9JM2UKvP22JtetrGwC/gbgFTO7zMwuA14Bro22LBEpBkce6euvzz037koklfJlZBMmxF1J7g0d6nM/fv3ruCspLtlMsrsfOBT4ApgDHBJCGBp1YSJSHNq08R3wJF7VW9UmbVe7JUt8/H3ffX14SLKXzSS7jYEPQgi3Am8C5TUn3YmISPw6doRevZI30W7cON97Qd3zKy+bsfTHgDIz2wS4C9+q9gFgnygLExGRlZNKwU03wQ8/eM9KsQkBvvnGl/vNnOnfH3/cN/LZd9+4qys+2QT80hDC4vQZ8DeHEG4xs0lRFyYiIisnlYLrroMXXyzcfQkWL4ZZs5aFeHWQV3//7rvl77/22j7HY5VV4qm3mGUT8IvMbCDwG/wseADtVyUiUmB22cVXNYwdG2/Az5u3fHDX/Pnjjz3kqzVvDl27+vK3HXf07xtv7N832qg4eyIKRTYB/ztgEHBFCOFDM+sKVERbloiIrKxWrTzko55ot3Sp715YWwt85sxfnmzXoYOHdlkZHHHE8iHeqZMmaUal3oAPIbwNnFbj8ofA1VEWJSIiDVNeDued5xPT1lmn4c/z44/w4Ye/DO8PPvDra54s2LSpb7Sz8cZwyCG/bIW3b9/otyUNoA1rREQSJJXygH/2WTjqqBXfLwT44ovaW+AffPDLUwNXXdVDu0cPOOCA5UN8gw100FAhUsCLiCTINtt4l/gzz8Bhh/khNLWF+MyZ3kqvZubd5Rtv7OP3NVvgG2/sa9B1yEtxUcCLiCRIkya+6c3QoXD//csfIduq1bLQLi9fvhXepYtmqidNvQFvZpsCg4ENa94/hNAvwrpERKSBBg+Gtm2967xmiK+zjlrhpSSbFvwjwB3AnUACjzEQEUmW7bbzLylt2QT84hDC7ZFXIiIiIjmTzWlyT5nZyWa2rpl1qP6KvDIRERFpsGxa8L9Nfx9c47oAbJT7ckRERCQXstnopms+ChEREZHcyWYWfXPgJGC39FXPA/8MISyKsC4RERFphGy66G/HD5f5R/ryMenrToiqKBEREWmcbAJ+uxBCzxqXx5nZlKgKEhERkcbLZhb9EjPbuPqCmW2E1sOLiIgUtGxa8IOB58xsJmD4jna/i7QqERERaZRsZtE/a2bdgM3wgH8nhPBz5JWJiIhIg60w4M2sXwhhnJkdknHTxmZGCOHxiGsTERGRBqqrBb87MA7Yv5bbAqCAFxERKVArDPgQwsXpHy8NIXxY8zYz0+Y3IiIiBSybWfSP1XLdo7kuRERERHKnrjH4zYEeQLuMcfjVgFWiLkxEREQarq4x+M2A/YD2LD8O/z3w+whrEhERkUaqawz+38C/zWzHEMKreaxJREREGimbjW4mmdkpeHf9/3fNhxCOi6wqERERaZRsJtkNBdYB9gReADrj3fQiIiJSoLIJ+E1CCBcCP4QQ/gXsC2wVbVkiIiLSGNkEfPW579+a2ZZAO6BLZBWJiIhIo2UzBj/EzFYHLgRGAG2BiyKtSkRERBolm8Nm7kr/+AKwUbTliIiISC7UtdHNWXU9MIRwY+7LERERkVyoqwW/avr7ZsB2ePc8+KY3L0ZZlIiIiDROXRvdXAJgZmOAbUMI36cv/xV4JC/ViYiISINkM4t+A2BhjcsL0Sx6ERGRgpbNLPqhwHgzewI/B/5g4P5IqxIREZFGyWYW/RVmVgnsmr7qdyGESdGWJSIiIo2xwi56M1st/b0D8BHekh8KfJy+rl5mtpeZvWtmM8zs3Fpu72tm35nZ5PTXRRm3NzWzSWb29Eq8JxERkZJXVwv+Afy42Al413w1S1+uc028mTUFbgNSwGzgDTMbEUJ4O+OuL4UQ9lvB05wOTMfPoBcREZEs1TWLfr/0964NfO4+wIwQwkwAMxsOHAhkBnytzKwzvu/9FUCda/JFRERkeXVtdLNtXQ8MIUys57k7AbNqXJ4NbF/L/XY0synAZ8A5IYRp6etvAv7EsvX4K6rzROBEgA022KCekkREREpDXV30N9RxWwD61fPctoLH1TQR2DCEMN/M9gGeBLqZ2X7AnBDCBDPrW9eLhBCGAEMAysrKMp9fRESkJNXVRb9HI597NrB+jcud8VZ6zdeYV+PnkWb2DzNbE9gZOCAd+qsAq5lZRQjh6EbWJCIiUhKyWQdP+pjY7njYAhBCqG8t/Bt4a7wr8CkwADgy43nXAb4IIQQz64PP6v8qhHAecF76Pn3xrnuFu4iISJbqDXgzuxjoiwf8SGBv4GXq2ewmhLDYzP4IjAaaAveEEKaZ2aD07XcAhwEnmdliYAEwIISgbnYREZFGsvry1MzeBHoCk0IIPc1sbeCuEML++ShwZZSVlYWqqqq4yxAREckLM5sQQiir7bZs9qJfEEJYCixOb34zB50LLyIiUtCyGYOvMrP2wJ34pjfzgfFRFiUiIiKNU9c6+FuBB0IIJ6evusPMRgGrhRCm5qU6ERERaZC6WvDvAzeY2brAQ8CDIYTJealKREREGmWFY/AhhJtDCDsCuwNfA/ea2XQzu8jMNs1bhSIiIrLS6p1kF0L4OIRwTQhhG3wd+8H4ATAiIiJSoOoNeDNrbmb7m9kwoBJ4Dzg08spERESkweqaZJcCBuInuo0HhgMnhhB+yFNtIiIi0kB1TbI7Hz8T/pwQwtd5qkdERERyIMrDZkRERCQm2exkJyIiIkVGAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgSINeDPby8zeNbMZZnZuLbf3NbPvzGxy+uui9PXrm9lzZjbdzKaZ2elR1ikiIpI0zaJ6YjNrCtwGpIDZwBtmNiKE8HbGXV8KIeyXcd1i4OwQwkQzWxWYYGbP1PJYERERqUWULfg+wIwQwswQwkJgOHBgNg8MIfwvhDAx/fP3wHSgU2SVioiIJEyUAd8JmFXj8mxqD+kdzWyKmVWaWY/MG82sC7AN8HptL2JmJ5pZlZlVzZ07Nwdli4iIFL8oA95quS5kXJ4IbBhC6AncAjy53BOYtQUeA84IIcyr7UVCCENCCGUhhLKOHTs2vmoREZEEiDLgZwPr17jcGfis5h1CCPNCCPPTP48EmpvZmgBm1hwP92EhhMcjrFNERCRxogz4N4BuZtbVzFoAA4ARNe9gZuuYmaV/7pOu56v0dXcD00MIN0ZYo4iISCJFNos+hLDYzP4IjAaaAveEEKaZ2aD07XcAhwEnmdliYAEwIIQQzGwX4BjgTTObnH7K89OtfBEREamHhZA5LF68ysrKQlVVVdxliIiI5IWZTQghlNV2m3ayExERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EXybcEC2Hdf2HpreO65uKsRkYRSwIvk04IFcOCBUFkJX38N/frB0UfD55/HXZmIJIwCXiRffvoJDj4Yxo6Fe+6B99+HCy+ERx6BzTaDW26BxYvjrlJEEkIBL5IPP/8Mhx4Ko0fDXXfBscdCq1Zw6aXw1luwww5w2mnQpw+89lrc1YpIAijgRaL2889w2GEwciQMGQLHHbf87d26wahR8PDDMGcO7LgjnHgifPVVPPWKSCJEGvBmtpeZvWtmM8zs3Fpu72tm35nZ5PTXRdk+VqQoLFwIhx8OTz8Nt98Ov/997fczg1//GqZPh7PP9i78zTaDu++GpUvzW7OIJEJkAW9mTYHbgL2B7sBAM+tey11fCiH0Sn9dupKPFSlcixbBEUfAiBFw220waFD9j1l1Vbj+epg0CTbfHE44AXbZBaZMib5eEUmUKFvwfYAZIYSZIYSFwHDgwDw8ViR+ixbBgAHw5JM+ee7kk1fu8VttBS++CPfe65PxeveGM8+EefMiKVdEkifKgO8EzKpxeXb6ukw7mtkUM6s0sx4r+VjM7EQzqzKzqrlz5+aibpHGWbwYjjoKHn8cbroJ/vjHhj1PkyY+Ge/dd71r/+abvVU/fDiEkMuKRSSBogx4q+W6zL9KE4ENQwg9gVuAJ1fisX5lCENCCGUhhLKOHTs2tFaR3Fi82Ne1P/II3HADnH5645+zQwcfv3/9dVhvPRg4EFIpD34RkRWIMuBnA+vXuNwZ+KzmHUII80II89M/jwSam9ma2TxWpOAsXgy/+Q089BBcdx2cdVZun3+77Tzkb7sNqqq8G/8vf4Eff8zt64hIIkQZ8G8A3cysq5m1AAYAI2rewczWMTNL/9wnXc9X2TxWpKAsWeLd6Q8+CFdfDeecE83rNG3q4/nvvust+SuvhO7d4amnonk9ESlakQV8CGEx8EdgNDAdeDiEMM3MBplZ9XTiw4C3zGwK8HdgQHC1PjaqWkUaZckSX9s+bBhccQX8+c/Rv+baa8O//gXPPw9t2sABB/jXRx9F/9oiUhQsJGiyTllZWaiqqsrNkx17LLRtC7vu6l/rrZeb55VkWboUjj8e7rvPd6W78ML817BokU/A++tfvZ4LLvC19C1b5r8WEckrM5sQQiir7TbtZFebEGDuXP+jPWAAdOoEG20Ev/2tbzP67ruaxSwepiee6P9OLr44nnAHaN7chwSmT4d99vFx+a239j3vRaRkqQVfl0WLYPJkePlleOkl/169FK9jR9+AZJddvIW/zTbQrFnuXlsK29KlvnHNnXd6sF9yie9GVwhGjfKleR984B9Qb7hBPVAiCVVXC14BvzJCgPfe87CvDvyZM/22Nm38wJDqLv3tt/frJHlC8Ilud9wB558Pl19eOOFe7aef4Jpr4KqroEULuOwyOOUUfQgVSRgFfJQ+/dSDvrqVP3WqB0CzZrDtth721S39NdfMb22SeyF46/gf//DJdFddVXjhXtMHH3i9o0ZBz55e9047xV2ViOSIAj6fvv0WXn11WSt//Hg/cARgiy2WdenvuitsuGFhh4MsLwTfuOaWW3zM+9pri+P/XwjwxBNe++zZPinw6qv1gVMkARTwcfrpJ9+UpLpL/7//he++89s6dVoW9rvsAltu6duTSuEJwfeCv/lm/37DDcUR7jXNn+9d9TfeCKut5iF//PH6NydSxBTwhWTJEnjrrWVd+i+9BJ+lN+lr3967T6tDv6xMS50KQQjeYr/xRm8F/+1vxRfuNU2b5nMIXnzR54rcfrtPEhWRoqOAL2Qh+OYkNSfuvfOO39ayJfTps6yFv9NO0K5drOWWnBB8rP266+DUU70FX8zhXi0EqKjwDy5ffukT8C67TP++RIqMAr7YzJ27/MS9iRO95d+kia9vrjmOv+66cVebXCH4LPmrr/YW7623JiPca/r2W98Y5x//gLXW8qGHI49M3vsUSSgFfLH74Qd47bVlrfzXXlt2wMhGGy0/jr/ppvrjnAshePBdeSX84Q8egEkeq54wAU46Cd54A/r29fe7xRZxVyUi9VDAJ82iRTBp0rIu/Zdf9m5W8FZYzQ14evXS2ueGuOgi77I+4QT45z+THe7VlizxnRrPOw++/963u73wQu3nIFLAFPBJF4KP29fcce/DD/22Nm187P7kk+HAA9W6z8Yll/i+7scd5zvVlUK41zR3rs87uPde2GADn3egfzsiBUl70SedmXen/v73cP/9vrverFl+dOmxx8KMGXDwwX6e+MiR2ke/Lpdf7uF+7LGlGe7g2zDfc49/WGzXzv/t7Lffsl0bRaQolOBfrxLRubPvQ37rrb697r33wtdfw777eov+mWcU9JmuvNK7pI85xruqSzHca9plFx+bv/FGX1LXo4cPW/z8c9yViUgWSvwvWIlo1sxbpO+84+PJs2fDr37lk6lefDHu6grDNdf4KWxHHeUfhpo2jbuiwtC8uW/s8847ft78RRfBVlvBmDFxVyYi9VDAl5IWLfx40/ffh7//3Vv2u+8OqZTPzC9V118P557rPR733adwr02nTvDQQ8uCfc894fDD/SwGESlICvhStMoqvmnLBx/4uucpU2DHHb37fsKEuKvLr7/9DQYP9rAaOlQrDuqTSsGbb3pX/VNPweabexf+okVxVyYiGRTwpax1azjrLJ88ddVVfkhOWZlPqpo6Ne7qonfzzf7+DzsMhg1TuGerZUvfI+Dtt70H6OyzvRtfRAqKAl6gbVvvov7oI18iNm6cHy16xBEwfXrc1UXj1lvhjDPgkEPggQcU7g3Rtau34p98UgEvUoAU8LLMaqv5JKoPP/QtWv/zHz/h7phjfKldUvzjHz5EceCBvpSwefO4KypeZv7fceON465ERDIo4OWXOnSAK67woD/rLHjsMR9rPf54b+UXs3/+0w9W2X9/ePhhn3goIpJACnhZsY4d/RS1mTM9FIcN873uTzrJl9oVmzvvhEGDfDLhI48o3EUk0RTwUr911vEJaTNm+N7sd98Nm2ziZ6N//nnc1WXnnnt8ieDee3uPRMuWcVckIhIpBbxkr3NnH79+7z3fEOa22/w0u8GDff/yQnXfff7BZM894fHHFe4iUhIU8LLyunTxVvw778Chh/pa+o028p3gvvkm7uqWd//9fmhMeTk88YTvASAiUgIU8NJwm2zim8NMmwb77ON7uXftCpdeCvPmxV2dzxk49ljo18+XcrVqFXdFIiJ5o4CXxttiC9/GdMoU2GMPuPhiD/qrr4b58+Op6cEH4Te/8f32R4zwTX1EREqIAl5yZ+utvRu8qgp22AHOO8+77m+8ERYsyF8dDz0ERx8Nu+7qG7Eo3EWkBCngJfd69/ZNcl55xXfEO/tsD/pbb43+qNFHHvEJgDvvDE8/DW3aRPt6IiIFSgEv0dlxRz93/oUXfP38qadCt24wZEg0h5M8/jgMHOi9B//5j2/BKyJSohTwEr3ddoPnn/ew79QJ/vAH2GwzX762eHFuXuPJJ33v/D59YORIWHXV3DyviEiRUsBLfpj5UrVXXvHWdYcO8LvfQY8eftjLkiUNf+4RI/y41969YdQo31NfRKTEKeAlv8x8Sd0bb/iEvJYtfcx8663h0Udh6dKVe76nn/bjXnv1gtGjFe4iImkKeImHGRx0EEye7LPely6FX/8att3WW+Qh1P8cI0f6Rjtbbw1jxkC7dlFXLSJSNBTwEq8mTbx7/a23fNOcH37w40e3396721cU9KNH+1nuPXp4uLdvn9eyRUQKnQJeCkPTpr52ffp03wZ3zhw/GGaXXWDcuOXvO2aMfwjYYgsYO9bH80VEZDkKeCkszZr53vHvvQe33w4ffwz9+/sOeS+/7IF+4IE+C1/hLiKyQgp4KUwtWvjZ7TNm+FG106f7znR77eV74I8dC2usEXeVIiIFSwEvhW2VVeC002DmTLjuOp+Y9+yz0LFj3JWJiBS0ZnEXIJKV1q3hnHPirkJEpGioBS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVERBJIAS8iIpJACngREZEEshBC3DXkjJnNBT7O4VOuCXyZw+eLU1LeS1LeB+i9FKqkvJekvA/Qe6nLhiGEjrXdkKiAzzUzqwohlMVdRy4k5b0k5X2A3kuhSsp7Scr7AL2XhlIXvYiISAIp4EVERBJIAV+3IXEXkENJeS9JeR+g91KokvJekvI+QO+lQTQGLyIikkBqwYuIiCSQAr4WZraXmb1rZjPM7Ny462kMM7vHzOaY2Vtx19IYZra+mT1nZtPNbJqZnR53TQ1lZquY2Xgzm5J+L5fEXVNjmFlTM5tkZk/HXUtjmNlHZvammU02s6q462kMM2tvZo+a2Tvp35kd466pIcxss/T/j+qveWZ2Rtx1NYSZnZn+fX/LzB40s1Uif0110S/PzJoC7wEpYDbwBjAwhPB2rIU1kJntBswH7g8hbBl3PQ1lZusC64YQJprZqsAE4KBi/P9iZga0CSHMN7PmwMvA6SGE12IurUHM7CygDFgthLBf3PU0lJl9BJSFEIp+vbWZ/Qt4KYRwl5m1AFqHEL6NuaxGSf9t/hTYPoSQy/1OImdmnfDf8+4hhAVm9jAwMoRwX5Svqxb8L/UBZoQQZoYQFgLDgQNjrqnBQggvAl/HXUdjhRD+F0KYmP75e2A60CneqhomuPnpi83TX0X5SdvMOgP7AnfFXYs4M1sN2A24GyCEsLDYwz2tP/BBsYV7Dc2AVmbWDGgNfBb1Cyrgf6kTMKvG5dkUaZAklZl1AbYBXo+5lAZLd2tPBuYAz4QQivW93AT8CVgacx25EIAxZjbBzE6Mu5hG2AiYC9ybHjq5y8zaxF1UDgwAHoy7iIYIIXwKXA98AvwP+C6EMCbq11XA/5LVcl1Rtq6SyMzaAo8BZ4QQ5sVdT0OFEJaEEHoBnYE+ZlZ0wydmth8wJ4QwIe5acmTnEMK2wN7AKenhrWLUDNgWuD2EsA3wA1Dsc4laAAcAj8RdS0OY2ep4T3BXYD2gjZkdHfXrKuB/aTawfo3LnclDV4rULz1e/RgwLITweNz15EK66/R5YK94K2mQnYED0mPXw4F+ZlYRb0kNF0L4LP19DvAEPlxXjGYDs2v0Cj2KB34x2xuYGEL4Iu5CGqgc+DCEMDeEsAh4HNgp6hdVwP/SG0A3M+ua/tQ4ABgRc00lLz0x7W5gegjhxrjraQwz62hm7dM/t8J/+d+JtagGCCGcF0LoHELogv+ejAshRN4qiYKZtUlP3iTdnf0roChXnoQQPgdmmdlm6av6A0U3GTXDQIq0ez7tE2AHM2ud/lvWH59HFKlmUb9AsQkhLDazPwKjgabAPSGEaTGX1WBm9iDQF1jTzGYDF4cQ7o63qgbZGTgGeDM9dg1wfghhZHwlNdi6wL/Ss4KbAA+HEIp6iVkCrA084X97aQY8EEIYFW9JjXIqMCzdSJkJ/C7mehrMzFrjq5r+EHctDRVCeN3MHgUmAouBSeRhRzstkxMREUkgddGLiIgkkAJeREQkgRTwIiIiCaSAFxERSSAFvIiISAIp4EVKnJktyTixK2e7nplZl2I/yVCkWGkdvIgsSG+bKyIJoha8iNQqfT76Nemz68eb2Sbp6zc0s2fNbGr6+wbp69c2syfS59xPMbPqrTibmtmd6bOwx6R378PMTjOzt9PPMzymtymSWAp4EWmV0UV/RI3b5oUQ+gC34ifHkf75/hDC1sAw4O/p6/8OvBBC6InvfV69A2Q34LYQQg/gW+DQ9PXnAtukn2dQNG9NpHRpJzuREmdm80MIbWu5/iOgXwhhZvqgn89DCGuY2ZfAuiGERenr/xdCWNPM5gKdQwg/13iOLvhxuN3Sl/8MNA8hXG5mo4D5wJPAkyGE+RG/VZGSoha8iNQlrODnFd2nNj/X+HkJy+b+7AvcBvQGJpiZ5gSJ5JACXkTqckSN76+mf34FPz0O4Cjg5fTPzwInAZhZUzNbbUVPamZNgPVDCM8BfwLaA7/oRRCRhtMnZhFpVeOEPoBRIYTqpXItzex1vDEwMH3dacA9ZjYYmMuyk8pOB4aY2fF4S/0k4H8reM2mQIWZtQMM+FsI4dscvR8RQWPwIrIC6TH4shDCl3HXIiIrT130IiIiCaQWvIiISAKpBS8iIpJACngREZEEUsCLiIgkkAJeREQkgRTwIiIiCaSAFxERSaD/A31cH29epkUsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation=\"relu\", input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation=\"relu\"))\n",
    "model_2.add(Dense(50, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112fb1",
   "metadata": {},
   "source": [
    "note: The blue model is the one you made and the red is the original model. The model with the lower loss value is the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e46e5c",
   "metadata": {},
   "source": [
    "#### Thinking about model capacity\n",
    "- Overfitting\n",
    "![](img11.png)\n",
    "- Workflow for optimizing model capacity\n",
    "    - Start with a small network\n",
    "    - Gradually increase capacity\n",
    "    - Keep increasing capacity until validation score is no longer improving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c657f5",
   "metadata": {},
   "source": [
    "#### Question: Experimenting with model structures\n",
    "You've just run an experiment where you compared two networks that were identical except that the 2nd network had an extra hidden layer. You see that this 2nd network (the deeper network) had better performance. Given that, which of the following would be a good experiment to run next for even better performance?\n",
    "\n",
    "\n",
    " - Answer: Use more units in each hidden layer. ! Increasing the number of units in each hidden layer would be a good next step to try achieving even better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d113f72",
   "metadata": {},
   "source": [
    "\n",
    "#### Building your own digit recognition model\n",
    "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\n",
    "\n",
    "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from Keras are also pre-imported.\n",
    "\n",
    "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\n",
    "\n",
    "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a blog post by Dan that explains how to do this - check it out after completing this exercise! It is a great next step as you continue your deep learning journey.\n",
    "\n",
    "Ready to take your deep learning to the next level? Check out `Advanced Deep Learning with Keras` to see how the Keras functional API lets you build domain knowledge to solve new types of problems. Once you know how to use the functional API, take a look at `Image Processing with Keras in Python` to learn image-specific applications of Keras.\n",
    "\n",
    " - reate a Sequential object to start your model. Call this `model`.\n",
    " - Add the first Dense hidden layer of `50 units` to your model with `'relu' activation`. For this data, the` input_shape` is `(784,)`.\n",
    " - Add a second Dense hidden layer with `50 units` and a `'relu' activation` function.\n",
    " - Add the `output layer`. Your activation function should be `'softmax'`, and the number of nodes in this layer should be the same as the number of possible outputs in this `case: 10`.\n",
    " - Compile model as you have done with previous models: Using `'adam'` as the `optimizer`, `'categorical_crossentropy' `for the `loss`, and `metrics=['accuracy']`.\n",
    " - Fit the model using `X` and `y` using a `validation_split` of `0.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2dadcd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...    775    776   777  \\\n",
       "0    5    0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.61   \n",
       "1    4    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "2    3    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "3    0    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "4    2    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "\n",
       "     778    779    780    781    782    783    784  \n",
       "0  0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "1  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "2  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "3  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "4  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv('./dataset/mnist.csv', header=None)\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddee2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.iloc[:, 1:].astype(np.float32).to_numpy()\n",
    "y = to_categorical(mnist.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c1c3ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 601 samples\n",
      "Epoch 1/50\n",
      " 736/1400 [==============>...............] - ETA: 0s - loss: 30.3274 - acc: 0.3030     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 1s 426us/sample - loss: 20.1157 - acc: 0.4286 - val_loss: 7.4471 - val_acc: 0.5890\n",
      "Epoch 2/50\n",
      "1400/1400 [==============================] - 0s 117us/sample - loss: 3.9758 - acc: 0.6914 - val_loss: 4.9587 - val_acc: 0.6356\n",
      "Epoch 3/50\n",
      "1400/1400 [==============================] - 0s 119us/sample - loss: 2.1938 - acc: 0.7764 - val_loss: 4.4858 - val_acc: 0.6855\n",
      "Epoch 4/50\n",
      "1400/1400 [==============================] - 0s 123us/sample - loss: 1.4364 - acc: 0.8164 - val_loss: 4.1727 - val_acc: 0.6872\n",
      "Epoch 5/50\n",
      "1400/1400 [==============================] - 0s 117us/sample - loss: 0.8177 - acc: 0.8729 - val_loss: 4.5599 - val_acc: 0.6955\n",
      "Epoch 6/50\n",
      "1400/1400 [==============================] - 0s 103us/sample - loss: 0.6274 - acc: 0.9021 - val_loss: 3.8151 - val_acc: 0.7271\n",
      "Epoch 7/50\n",
      "1400/1400 [==============================] - 0s 98us/sample - loss: 0.3344 - acc: 0.9279 - val_loss: 3.5669 - val_acc: 0.7471\n",
      "Epoch 8/50\n",
      "1400/1400 [==============================] - 0s 115us/sample - loss: 0.2392 - acc: 0.9507 - val_loss: 3.6569 - val_acc: 0.7421\n",
      "Epoch 9/50\n",
      "1400/1400 [==============================] - 0s 120us/sample - loss: 0.1596 - acc: 0.9571 - val_loss: 3.4690 - val_acc: 0.7504\n",
      "Epoch 10/50\n",
      "1400/1400 [==============================] - 0s 120us/sample - loss: 0.1031 - acc: 0.9721 - val_loss: 3.8636 - val_acc: 0.7438\n",
      "Epoch 11/50\n",
      "1400/1400 [==============================] - 0s 110us/sample - loss: 0.1118 - acc: 0.9707 - val_loss: 3.5506 - val_acc: 0.7488\n",
      "Epoch 12/50\n",
      "1400/1400 [==============================] - 0s 113us/sample - loss: 0.1035 - acc: 0.9757 - val_loss: 3.5484 - val_acc: 0.7504\n",
      "Epoch 13/50\n",
      "1400/1400 [==============================] - 0s 113us/sample - loss: 0.0955 - acc: 0.9757 - val_loss: 3.6434 - val_acc: 0.7388\n",
      "Epoch 14/50\n",
      "1400/1400 [==============================] - 0s 103us/sample - loss: 0.0774 - acc: 0.9771 - val_loss: 3.6076 - val_acc: 0.7571\n",
      "Epoch 15/50\n",
      "1400/1400 [==============================] - 0s 91us/sample - loss: 0.0650 - acc: 0.9821 - val_loss: 3.5586 - val_acc: 0.7687\n",
      "Epoch 16/50\n",
      "1400/1400 [==============================] - 0s 95us/sample - loss: 0.0484 - acc: 0.9821 - val_loss: 3.5365 - val_acc: 0.7671\n",
      "Epoch 17/50\n",
      "1400/1400 [==============================] - 0s 113us/sample - loss: 0.0205 - acc: 0.9936 - val_loss: 3.5971 - val_acc: 0.7720\n",
      "Epoch 18/50\n",
      "1400/1400 [==============================] - 0s 112us/sample - loss: 0.0056 - acc: 0.9993 - val_loss: 3.6196 - val_acc: 0.7820\n",
      "Epoch 19/50\n",
      "1400/1400 [==============================] - 0s 107us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 3.4850 - val_acc: 0.7820\n",
      "Epoch 20/50\n",
      "1400/1400 [==============================] - 0s 93us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 3.4675 - val_acc: 0.7820\n",
      "Epoch 21/50\n",
      "1400/1400 [==============================] - 0s 97us/sample - loss: 5.3771e-04 - acc: 1.0000 - val_loss: 3.4684 - val_acc: 0.7837\n",
      "Epoch 22/50\n",
      "1400/1400 [==============================] - 0s 92us/sample - loss: 4.6428e-04 - acc: 1.0000 - val_loss: 3.4689 - val_acc: 0.7837\n",
      "Epoch 23/50\n",
      "1400/1400 [==============================] - 0s 97us/sample - loss: 4.2449e-04 - acc: 1.0000 - val_loss: 3.4668 - val_acc: 0.7820\n",
      "Epoch 24/50\n",
      "1400/1400 [==============================] - 0s 115us/sample - loss: 3.9184e-04 - acc: 1.0000 - val_loss: 3.4675 - val_acc: 0.7820\n",
      "Epoch 25/50\n",
      "1400/1400 [==============================] - 0s 124us/sample - loss: 3.6647e-04 - acc: 1.0000 - val_loss: 3.4659 - val_acc: 0.7837\n",
      "Epoch 26/50\n",
      "1400/1400 [==============================] - 0s 109us/sample - loss: 3.4318e-04 - acc: 1.0000 - val_loss: 3.4625 - val_acc: 0.7837\n",
      "Epoch 27/50\n",
      "1400/1400 [==============================] - 0s 110us/sample - loss: 3.2479e-04 - acc: 1.0000 - val_loss: 3.4608 - val_acc: 0.7854\n",
      "Epoch 28/50\n",
      "1400/1400 [==============================] - 0s 110us/sample - loss: 3.0837e-04 - acc: 1.0000 - val_loss: 3.4600 - val_acc: 0.7820\n",
      "Epoch 29/50\n",
      "1400/1400 [==============================] - 0s 101us/sample - loss: 2.9493e-04 - acc: 1.0000 - val_loss: 3.4617 - val_acc: 0.7837\n",
      "Epoch 30/50\n",
      "1400/1400 [==============================] - 0s 101us/sample - loss: 2.8063e-04 - acc: 1.0000 - val_loss: 3.4608 - val_acc: 0.7837\n",
      "Epoch 31/50\n",
      "1400/1400 [==============================] - 0s 91us/sample - loss: 2.6915e-04 - acc: 1.0000 - val_loss: 3.4608 - val_acc: 0.7837\n",
      "Epoch 32/50\n",
      "1400/1400 [==============================] - 0s 93us/sample - loss: 2.5792e-04 - acc: 1.0000 - val_loss: 3.4583 - val_acc: 0.7837\n",
      "Epoch 33/50\n",
      "1400/1400 [==============================] - 0s 101us/sample - loss: 2.4814e-04 - acc: 1.0000 - val_loss: 3.4606 - val_acc: 0.7837\n",
      "Epoch 34/50\n",
      "1400/1400 [==============================] - 0s 93us/sample - loss: 2.3794e-04 - acc: 1.0000 - val_loss: 3.4582 - val_acc: 0.7837\n",
      "Epoch 35/50\n",
      "1400/1400 [==============================] - 0s 96us/sample - loss: 2.2928e-04 - acc: 1.0000 - val_loss: 3.4583 - val_acc: 0.7837\n",
      "Epoch 36/50\n",
      "1400/1400 [==============================] - 0s 93us/sample - loss: 2.2183e-04 - acc: 1.0000 - val_loss: 3.4584 - val_acc: 0.7837\n",
      "Epoch 37/50\n",
      "1400/1400 [==============================] - 0s 90us/sample - loss: 2.1287e-04 - acc: 1.0000 - val_loss: 3.4564 - val_acc: 0.7837\n",
      "Epoch 38/50\n",
      "1400/1400 [==============================] - 0s 99us/sample - loss: 2.0561e-04 - acc: 1.0000 - val_loss: 3.4545 - val_acc: 0.7854\n",
      "Epoch 39/50\n",
      "1400/1400 [==============================] - 0s 91us/sample - loss: 1.9916e-04 - acc: 1.0000 - val_loss: 3.4564 - val_acc: 0.7820\n",
      "Epoch 40/50\n",
      "1400/1400 [==============================] - 0s 102us/sample - loss: 1.9196e-04 - acc: 1.0000 - val_loss: 3.4525 - val_acc: 0.7837\n",
      "Epoch 41/50\n",
      "1400/1400 [==============================] - 0s 105us/sample - loss: 1.8495e-04 - acc: 1.0000 - val_loss: 3.4551 - val_acc: 0.7820\n",
      "Epoch 42/50\n",
      "1400/1400 [==============================] - 0s 109us/sample - loss: 1.7838e-04 - acc: 1.0000 - val_loss: 3.4556 - val_acc: 0.7820\n",
      "Epoch 43/50\n",
      "1400/1400 [==============================] - 0s 118us/sample - loss: 1.7294e-04 - acc: 1.0000 - val_loss: 3.4528 - val_acc: 0.7820\n",
      "Epoch 44/50\n",
      "1400/1400 [==============================] - 0s 107us/sample - loss: 1.6775e-04 - acc: 1.0000 - val_loss: 3.4531 - val_acc: 0.7820\n",
      "Epoch 45/50\n",
      "1400/1400 [==============================] - 0s 115us/sample - loss: 1.6231e-04 - acc: 1.0000 - val_loss: 3.4509 - val_acc: 0.7820\n",
      "Epoch 46/50\n",
      "1400/1400 [==============================] - 0s 119us/sample - loss: 1.5497e-04 - acc: 1.0000 - val_loss: 3.4527 - val_acc: 0.7820\n",
      "Epoch 47/50\n",
      "1400/1400 [==============================] - 0s 109us/sample - loss: 1.5015e-04 - acc: 1.0000 - val_loss: 3.4513 - val_acc: 0.7820\n",
      "Epoch 48/50\n",
      "1400/1400 [==============================] - 0s 103us/sample - loss: 1.4491e-04 - acc: 1.0000 - val_loss: 3.4489 - val_acc: 0.7820\n",
      "Epoch 49/50\n",
      "1400/1400 [==============================] - 0s 90us/sample - loss: 1.4022e-04 - acc: 1.0000 - val_loss: 3.4506 - val_acc: 0.7820\n",
      "Epoch 50/50\n",
      "1400/1400 [==============================] - 0s 100us/sample - loss: 1.3573e-04 - acc: 1.0000 - val_loss: 3.4499 - val_acc: 0.7820\n"
     ]
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', input_shape=(X.shape[1], )))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3, epochs=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10edaf",
   "metadata": {},
   "source": [
    "note: You've done something pretty amazing. You should see better than 90% accuracy recognizing handwritten digits, even while using a small training set of only 1750 images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ff72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
